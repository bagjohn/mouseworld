
# coding: utf-8

# In[4]:

get_ipython().run_cell_magic('writefile', 'mouseworld/mouseworld.py', '\nfrom mesa import Agent, Model\n#from mesa.time import RandomActivation\n#from mesa.space import ContinuousSpace\nfrom mesa.datacollection import DataCollector\n\nimport itertools\nimport numpy as np\nimport math\nimport pandas as pd\nimport random\nfrom scipy.stats import norm\n\n# from mouseworld.myspace import ContinuousSpace\n# from mouseworld.myspace import Value_layer\nfrom mouseworld.mytime import *\nfrom mouseworld.myspace import *\nfrom mouseworld.mouse import Mouse\nfrom mouseworld.food import Food\nfrom mouseworld.predator import Predator\nfrom mouseworld.mydatacollector import MyDataCollector\n#from mouseworld.space_surface import Space_surface\n\nfrom joblib import Parallel, delayed\nimport multiprocessing\n\nclass Mouseworld(Model):\n    def __init__(self, num_mice, num_food, num_predators, width, height):\n        \n        # for parallel processing\n        self.num_cores = multiprocessing.cpu_count()\n        \n        # define model variables from args\n        self.num_mice = sum(num_mice)\n        self.num_unborn_mice = 0\n        self.num_genes = 5\n        self.num_food = num_food\n        self.num_predators = num_predators\n        # build model continuous space\n        self.space = ContinuousSpace(width, height, True, x_min=0, y_min=0,\n            grid_width=width, grid_height=height)\n        \n        # initialize genome\n        self.initialization_genome = self.initialize_genome()\n        \n        # initialize food parameters\n        self.food_amount_range = (20,200)\n        self.food_odor_strength = [1] #[0.7,1]\n        self.food_odor_std = [8]\n        self.nutritional_value = [-1, 0.7, 1]\n        self.food_params = (self.food_odor_strength, self.nutritional_value, self.food_odor_std)\n        self.food_param_combs = list(itertools.product(*self.food_params))\n        self.food_groups_num = len(self.food_param_combs)\n        self.food_groups = [(\'Food_group_%i\'%i) for i in range(self.food_groups_num)]\n        self.food_layers = [Value_layer(\'Food_odor_%i\'%i, width, height, True) for i in range(self.food_groups_num)]\n        self.food_layer_names = [(\'Food_odor_%i\'%i) for i in range(self.food_groups_num)]\n#         for i in range(self.food_groups_num) :\n#             self.food_groups[i] = (\'Food_group_%i\'%i) \n#             self.food_layers[i] = (\'Food_odor_%i\'%i)\n        \n        # initialize predator parameters\n        self.predator_odor_strength = [1] # [0.7,1]\n        self.predator_odor_std = [8]\n        self.damage_level = [1] #[0.3,1]\n        self.hunt_rule = [0, 1]\n        self.hunt_radius = [0.5, 1] #[0.5,1]\n        self.predator_params = (self.predator_odor_strength, self.predator_odor_std, self.damage_level,\n                                self.hunt_rule, self.hunt_radius)\n        self.predator_param_combs = list(itertools.product(*self.predator_params))\n        self.predator_groups_num = len(self.predator_param_combs)\n        self.predator_groups = [(\'Predator_group_%i\'%i) for i in range(self.predator_groups_num)]\n        self.predator_layers = [Value_layer(\'Predator_odor_%i\'%i, width, height, True) for i in range(self.predator_groups_num)]\n        self.predator_layer_names = [(\'Predator_odor_%i\'%i) for i in range(self.predator_groups_num)]\n#         for i in range(self.predator_groups_num) :\n#             self.predator_groups[i] = (\'Predator_group_%i\'%i)\n#             self.predator_layers[i] = (\'Predator_odor_%i\'%i)\n            \n        # all agents (food & predator)\n        self.groups_num = self.food_groups_num + self.predator_groups_num\n        self.groups = self.food_groups + self.predator_groups\n        self.odor_layers = self.food_layers + self.predator_layers\n        self.odor_layer_names = self.food_layer_names + self.predator_layer_names\n\n        # build schedules\n        self.schedule = RandomActivation(self)\n        self.all_mice_schedule = RandomActivation(self)\n        self.food_schedule = RandomActivation(self)\n        self.predator_schedule = RandomActivation(self)\n        self.mouseworld_date = 0\n        \n        #initialize ids\n        self.initialize_ids([\'Mouse\', \'Food\', \'Predator\'])\n        \n        #initialize sensor_vector\n#         self.sensor_num = 2\n#         temp = [np.zeros(self.sensor_num)] * self.groups_num\n#         self.zero_sensor_vector = pd.Series(temp, index=self.odor_layers)\n        \n        # Create agents\n        for i in range(self.num_mice):\n            temp_genome = self.initialization_genome[i]\n            if i < num_mice[0] :\n                mouse = Mouse(self, None, temp_genome, 0, motor_NN_on = False, learning_on = False, appraisal_NN_on = False)\n            elif i < num_mice[1]:\n                mouse = Mouse(self, None, temp_genome, 0, motor_NN_on = True, learning_on = False, appraisal_NN_on = False)\n            else :\n                mouse = Mouse(self, None, temp_genome, 0, motor_NN_on = True, learning_on = True, appraisal_NN_on = False)\n            self.schedule.add(mouse)\n            self.all_mice_schedule.add(mouse)\n            self.place_agent_randomly(mouse)\n            #print(mouse.unique_id)\n            #print(mouse.genome)\n            \n        \n        for i in range(self.num_food):\n            j = i%(self.food_groups_num)\n            food = Food(self.food_groups[j], j, self.food_layers[j], self.food_amount_range, self)\n            self.food_schedule.add(food)\n            self.place_agent_randomly(food)\n            #self.food_layers[j].add_agent(food)\n            \n        for i in range(self.num_predators):\n            j = i%(self.predator_groups_num)\n            predator = Predator(self.predator_groups[j], j, self.predator_layers[j], self)\n            self.predator_schedule.add(predator)\n            self.place_agent_randomly(predator)\n            #self.predator_layers[j].add_agent(predator)\n                \n        self.initial_datacollector = MyDataCollector(\n            model_reporters={"Initial genome distribution": lambda a: a.initialization_genome})\n        \n#         self.datacollector = MyDataCollector(\n#             model_reporters={"Alive_mice": lambda a: a.num_mice, \n#                              "Unborn_mice": lambda a: a.num_unborn_mice}\n#             agent_reporters={"Header": lambda a: a.header,\n#                              "Age": lambda a: a.age, \n#                              "Energy": lambda a: a.energy,\n#                              "max_speed": lambda a: a.max_speed,\n#                              "incubation_period": lambda a: a.incubation_period,\n#                              "pos": lambda a: a.pos,\n#                              "Genome": lambda a: a.genome})\n        \n        self.model_datacollector = MyDataCollector(\n            model_reporters={"Alive_mice": lambda a: a.num_mice, \n                             "Unborn_mice": lambda a: a.num_unborn_mice})\n        \n        self.mousebrain_datacollector = MyDataCollector(\n            agent_reporters={"odor": lambda a: a.mousebrain_sim.data[a.mousebrain.p_odor],\n                             "state": lambda a: a.mousebrain_sim.data[a.mousebrain.p_state], \n                             "approach": lambda a: a.mousebrain_sim.data[a.mousebrain.p_approach],\n                             "avoid": lambda a: a.mousebrain_sim.data[a.mousebrain.p_avoid],\n                             "search": lambda a: a.mousebrain_sim.data[a.mousebrain.p_search],\n                             "change": lambda a: a.mousebrain_sim.data[a.mousebrain.p_change],\n                             "errors0": lambda a: a.mousebrain_sim.data[a.mousebrain.p_errors0],\n                             "errors1": lambda a: a.mousebrain_sim.data[a.mousebrain.p_errors1],\n                             "errors2": lambda a: a.mousebrain_sim.data[a.mousebrain.p_errors2]})\n\n        self.test_datacollector = MyDataCollector(\n            agent_reporters={"sensor_vector": lambda a: a.sensor_vector})       \n#         self.test_datacollector = MyDataCollector(\n#             agent_reporters={"sensor_vector": lambda a: a.sensor_vector,\n#                              "Action": lambda a: a.current_action[\'Verb\'],\n#                              "Noun_group": lambda a: a.current_action[\'Noun_group\'],\n#                              "food_gained_energy": lambda a: a.food_gained_energy,\n#                              "food_lost_energy": lambda a: a.food_lost_energy,\n#                              "metabolism_buffer": lambda a: a.metabolism_buffer,\n#                             "energy_to_predators": lambda a: a.energy_to_predators,\n#                             "total_distance": lambda a: a.total_distance})\n        \n#         self.final_datacollector = MyDataCollector(\n#             agent_reporters={"total_distance": lambda a: a.total_distance,\n#                              "Energy": lambda a: a.energy,\n#                              "food_lost_energy": lambda a: a.food_lost_energy,\n#                             "food_gained_energy": lambda a: a.food_gained_energy})\n        \n        self.final_datacollector = MyDataCollector(\n            model_reporters={"Alive_mice": lambda a: a.schedule.get_agent_count(), \n                             "All_mice": lambda a: a.all_mice_schedule.get_agent_count(), \n                             "Unborn_mice": lambda a: a.num_unborn_mice},\n            agent_reporters={"age": lambda a: a.age,\n                             "energy": lambda a: a.energy,\n                             "generation": lambda a: a.generation,\n                             "num_offspring": lambda a: a.num_offspring,\n                             "action_history": lambda a: a.action_history,\n                            "possible_actions": lambda a: a.possible_actions,\n                             "primary_values": lambda a: a.primary_values,\n                             "secondary_values": lambda a: a.secondary_values,\n                            "sensor_vector": lambda a: a.sensor_vector,\n                             "motor_vector": lambda a: a.motor_vector,\n                            "sensor_position": lambda a: a.sensor_position,\n                            "parent_ID": lambda a: a.parent_ID,\n                            "offspring": lambda a: a.offspring,\n                            "birth_date": lambda a: a.birth_date,\n                            "death_date": lambda a: a.death_date,\n                            "Genome": lambda a: a.genome})\n        \n        self.predator_datacollector = MyDataCollector(\n            agent_reporters={"Victims_num": lambda a: a.victims_num,\n                             "odor_strength": lambda a: a.odor_strength,\n                             "hunt_rule": lambda a: a.hunt_rule,\n                             "odor_std": lambda a: a.odor_std,\n                             "Damage_level": lambda a: a.damage_level})\n    \n#     def show_odor_to_mice(self, agent) :\n#         std = agent.odor_std\n#         agents_in_radius = self.space.get_neighbors(agent.pos, std*3, include_center=True)\n#         mice_in_radius = [x for x in agents_in_radius if isinstance (x, Mouse)]\n#         num_mice_in_radius = len(mice_in_radius)\n#         if len(mice_in_radius) != 0 :\n#             for mouse in mice_in_radius :\n#                 #get the appropriate odor value per sensor\n#                 odor_value = []\n#                 sensor_num = mouse.sensor_num\n#                 sensor_position = mouse.sensor_position\n#                 for i in range(sensor_num) :\n#                     pos = sensor_position[i]\n#                     distance = self.space.get_distance(agent.pos, pos)\n#                     odor_value.append(norm.pdf(distance, scale = std)*10)\n                    \n#                 # trivial transformation for test purposes\n#                 odor_value = (np.mean(odor_value), odor_value[0]-odor_value[1])\n                \n#                 #update the sensor vector\n#                 mouse.sensor_vector[agent.odor_layer] = odor_value\n                \n#                 #update the mouse\'s possible actions\n#                 self.update_mouse_possible_actions(mouse, mouse.possible_actions, agent.odor_layer, odor_value[0], agent)\n    \n#     def update_mouse_possible_actions (self, mouse, possible_actions, odor_layer, odor_value, agent) :\n#         #IMPORTANT : Primary (Food, Predator) and Secondary (Odor) values are a [x,y] where x is the reward and y the punishment\n#         # both positive\n        \n#         value = mouse.secondary_values[odor_layer]\n#         #mouse.possible_actions\n#         if value[0] > 0 :\n#             possible_actions.loc[possible_actions.index.max() + 1] = [\'Approach\', agent.group, odor_value * mouse.hunger_status * value[0], 0, 0, mouse.approach, odor_layer]\n#         if (value[1] > 0) & (isinstance (agent, Predator)) :\n#             possible_actions.loc[possible_actions.index.max() + 1] = [\'Avoid\', agent.group, 0, (-1) * odor_value * value[1], 0, mouse.avoid, odor_layer]\n\n#     def update_mouse_sensor_vector(self, mouse, odor_layer, odor_value) :\n#         sensor_vector = mouse.sensor_vector\n#         sensor_vector[odor_layer] = odor_value\n        \n    def initialize_ids(self, classes) :\n        self.next_ids = np.ones(1, dtype={\'names\':classes, \'formats\':[int]*len(classes)})\n            \n    def give_next_id(self, class_name) :\n        ind = int(self.next_ids[class_name])\n        next_id = \'%s_%i\'%(class_name, ind)\n        self.next_ids[class_name] += 1\n        return next_id\n        \n    def initialize_genome(self) :\n        genome = np.random.uniform(low=0.0, high=1.0, size=(self.num_mice, self.num_genes))\n        genome = np.around(genome, decimals = 2)\n        #print(genome)\n        return genome\n      \n    # Add the agent to a random space point\n    def place_agent_randomly(self, agent):\n        x = random.randrange(self.space.width)\n        y = random.randrange(self.space.height)\n        self.space.place_agent(agent, (x, y))\n#         if hasattr(agent, \'sensor_position\'):\n#             agent.set_sensor_position()\n    \n#     def update_surfaces(self) :\n#         for i in self.odor_layers :\n#             i.update_surface()\n    \n    def diffuse_odor_layers(self, layers) :\n        for layer in layers :\n            layer.diffuse(0.8,0.7) \n            \n    def diffuse_odor_layers_parallel(self, layers) :\n        \n        Parallel(n_jobs=self.num_cores)(delayed(layer.diffuse)(0.8,0.7) for layer in layers)\n            \n    def step(self):\n        \'\'\'Advance the model by one step.\'\'\'\n        #self.predator_datacollector.collect(self,self.predator_schedule)\n        self.food_schedule.step()\n        self.predator_schedule.step()\n        #self.diffuse_odor_layers_parallel(self.odor_layers)\n        self.diffuse_odor_layers(self.odor_layers)\n        self.schedule.step() \n        self.test_datacollector.collect(self, self.schedule)\n        self.model_datacollector.collect(self, self.schedule)\n        self.mouseworld_date += 1\n\n# class Agent_group :\n    \n#     def __init(self, model, parameters) :\n#         self.model = model\n#         self.parameters = parameters\n#         self.odor')


# In[5]:

get_ipython().run_cell_magic('writefile', 'mouseworld/mouse.py', "\nfrom mesa import Agent, Model\n#from mesa.time import RandomActivation\n#from mesa.space import ContinuousSpace\n\nimport nengo\nimport random\nimport math\nimport numpy as np\nimport pandas as pd\nfrom inspect import signature\n\nfrom mouseworld.myspace import ContinuousSpace\nfrom mouseworld.input_manager import Input_manager\n#from mouseworld.mousebrain import build_mousebrain\nfrom mouseworld.mousebrain import Mousebrain\n#import mouseworld.mousebrain\nfrom mouseworld.food import Food\n#from mouseworld.predator import Predator\nimport mouseworld.predator\n\n\nclass Mouse(Agent):\n    \n    def __init__(self, model, parent_ID, genome, generation, motor_NN_on, learning_on, appraisal_NN_on):\n        \n        # Initial parameter setting\n        self.model = model\n        self.unique_id = model.give_next_id('Mouse')\n        self.generation = generation\n        self.parent_ID = parent_ID\n        \n        # Constants\n        self.max_energy = 1200\n        self.max_gastric_content = 200\n        self.energy = 1000\n        self.maturity_age = 0       \n        self.metabolism_rate = 0.95\n        self.primary_learning_rate = 0.1\n        self.secondary_learning_rate = 0.01\n        self.conception_date = self.model.mouseworld_date\n        \n        # Constants per turn, for energy loss to predators and amount of food to consume. \n        self.suffering_amount = 20\n        self.feeding_amount = 20\n        \n        # Initialization of variables to be changed throughout life. Not to be retrieved\n        self.age = 0\n        self.death_date = None\n        self.birth_date = 0\n        self.energy_change = 0\n        self.metabolism_buffer = 0\n        self.gastric_content = 0\n        self.hunger_status = 1\n        self.incubation_time = 0   \n        self.pregnant = False\n        self.unborn = False\n        self.header = random.uniform(0, 2*math.pi)\n        #self.header = random.uniform(0, 2*math.pi)\n        self.unborn_child = None\n        self.num_offspring = 0\n        self.offspring = []\n        \n        # Initialization of cumulative counters. To be retrieved once per mouse        \n        self.energy_to_predators = 0\n        self.total_distance = 0\n        self.food_gained_energy = 0\n        self.food_lost_energy = 0\n        \n        # Genome to phenotype\n        self.genome = genome\n        self.max_speed = genome[0] * (5 - 1) + 1\n#         self.incubation_period = genome[1] * 200 + 100\n        self.incubation_period = genome[1] * 2 + 1\n        self.metabolism_range = genome[2]\n        self.antenna_length = genome[3]\n        self.antenna_angle = genome[4] * math.pi/2\n        \n        # Sensor and actor initialization\n        self.brain_iterations_per_step = 50\n        self.sensor_num = 2\n        self.sensor_vector = np.zeros(shape = (self.model.groups_num,self.sensor_num))\n        self.sensor_threshold = 0.0001\n        self.sensor_position = [(0,0)] * self.sensor_num\n        self.motor_num = 2\n        self.motor_vector = np.zeros(self.motor_num)\n        #self.possible_actions = [['wait'],['search_for_odor']]\n        #self.trivial_possible_actions = [self.wait(),self.search_for_odor()]\n        #self.current_action = [self.wait()]\n        self.trivial_actions = [['Wait', None, 0, self.wait, None], \n                                ['Search', None, 0.00001, self.search_for_odor, None]]\n        \n        self.possible_actions = pd.DataFrame(self.trivial_actions, \n                                                     columns=('Verb', 'Noun_group', 'Value', 'Function', 'Arg_1'))\n        \n        #self.current_action = self.possible_actions.loc[0]\n        self.action_history = pd.DataFrame([], columns=('Verb', 'Noun_group', 'Duration', 'Benefit', 'Termination', 'Distance'))\n#         self.action_history = pd.DataFrame([['Wait', None, 0, 0, False]], \n#                                            columns=('Verb', 'Noun_group', 'Duration', 'Benefit', 'Closure'))\n        \n        self.current_action = self.possible_actions.loc[0]\n#         self.action_value = pd.DataFrame([['Wait', np.nan, np.nan], ['Search', np.nan, np.nan]], \n#                                                      columns=('Verb', 'Noun_group', 'Value'))\n        \n        #self.primary_values = dict(zip(self.model.groups, [np.zeros(2)]*self.model.groups_num))\n        self.primary_values = dict(zip(self.model.groups, [1 for i in self.model.groups]))\n        self.secondary_values = pd.DataFrame([np.zeros(self.model.groups_num)] * self.model.groups_num, \n                                             index = self.model.groups, columns = self.model.odor_layer_names)\n        #self.secondary_values = dict(zip(self.model.groups, [np.zeros(self.model.groups_num)] * self.model.groups_num))\n        \n        # Mousebrain initialization\n        self.motor_NN_on = motor_NN_on\n        self.appraisal_NN_on = appraisal_NN_on\n        self.learning_on = learning_on\n        \n        if appraisal_NN_on:\n            pass\n        \n        if motor_NN_on :\n            self.input_manager = Input_manager()\n            self.mousebrain = Mousebrain()\n            self.mousebrain.build(self.input_manager)\n            self.mousebrain_sim = nengo.Simulator(self.mousebrain, dt=0.001)\n        \n    def die(self):\n        if (self.pregnant) :\n            #self.unborn_child.die()\n            self.model.num_unborn_mice -= 1\n        self.model.space.remove_agent(self)\n        self.model.schedule.remove(self)\n        self.action_history['Termination'][self.action_history.index.max()] = 'Death'\n        self.model.num_mice -= 1\n        self.death_age = self.age\n        self.death_date = self.model.mouseworld_date\n    \n    def mutate_genome(self) :\n        genome = self.genome\n        for i in range(len(genome)) :\n            rand = np.random.uniform(low=-1.0, high=1.0, size=None)\n            if abs(rand) <= 0.1 :\n                genome[i] += np.sign(rand) * 0.1\n                if genome[i] <= 0 :\n                    genome[i] = 0\n                elif genome[i] >= 1 :\n                    genome[i] = 1\n        return np.around(genome, decimals = 2)\n    \n    def conceive(self):\n        \n        # BIO : Genome passed to offspring \n        child_genome = self.mutate_genome()\n        \n        # BIO : New unborn mouse creation\n        mouse = Mouse(self.model, self.unique_id, child_genome, self.generation + 1, self.motor_NN_on, self.learning_on, self.appraisal_NN_on)\n        mouse.unborn = True\n        self.offspring.append(mouse)\n        \n        # BIO : Pass primary values to offspring (TEST)\n        mouse.primary_values = self.primary_values \n        \n        # BIO : Parent mouse pregnant\n        self.pregnant = True\n        self.unborn_child = mouse\n        \n        # COUNTER\n        self.model.num_unborn_mice += 1\n        \n        \n    def give_birth(self):\n        \n        # TECH : Place newborn in the world\n        self.model.place_agent_randomly(self.unborn_child)\n        self.model.schedule.add(self.unborn_child)\n        self.model.all_mice_schedule.add(self.unborn_child)\n        \n        # COUNTER\n        self.model.num_mice += 1\n        self.model.num_unborn_mice -= 1\n        self.num_offspring +=1\n        self.unborn_child.birth_date = self.model.mouseworld_date + 1\n        \n        # BIO : Parent no longer pregnant\n        self.pregnant = False\n        self.incubation_time = 0\n        self.unborn_child = None\n      \n    def set_sensor_position(self, pos, header) :\n        left_antenna_header = (header + self.antenna_angle) % (math.pi*2)\n        right_antenna_header = (header - self.antenna_angle) % (math.pi*2)\n        left_antenna_pos = (pos[0] + math.cos(left_antenna_header) * self.antenna_length, pos[1] + math.sin(left_antenna_header) * self.antenna_length)\n        right_antenna_pos = (pos[0] + math.cos(right_antenna_header) * self.antenna_length, pos[1] + math.sin(right_antenna_header) * self.antenna_length)\n        sensor_position = [self.model.space.torus_adj(left_antenna_pos), self.model.space.torus_adj(right_antenna_pos)]\n        for i in range(self.sensor_num) :\n            sensor_position[i]=self.model.space._point_to_cell(sensor_position[i])\n        return sensor_position\n    \n    def sense(self, pos) :\n        odor_layers = self.model.odor_layers\n        groups_num = self.model.groups_num\n#         for i in range(self.sensor_num) :\n#             pos[i]=self.model.space._point_to_cell(pos[i])\n        #sensor_vector = [[0] * self.sensor_num] * groups_num\n        sensor_vector = np.zeros(shape = (groups_num,self.sensor_num))\n        for i in range(groups_num) :\n            for j in range(self.sensor_num) :\n                temp = odor_layers[i].get_value(pos[j])\n                if temp > self.sensor_threshold :\n                    sensor_vector[i][j] = temp\n                else :\n                    sensor_vector[i][j] = 0\n            # trivial transformation for test purposes\n            sensor_vector[i] = [np.mean(sensor_vector[i]), sensor_vector[i][0]-sensor_vector[i][1]]\n        return sensor_vector      \n    \n    def update_possible_actions (self, actions) :\n        #a = self.trivial_possible_actions \n        temp = self.sensor_vector\n        groups = self.model.groups\n        #layer  = self.model.odor_layers\n        for i in range(len(temp)) :\n            if temp[i][0] > 0 :\n                # The secondary_values (as well as the primary_values) array, is indexed after model.groups_num.\n                # The sensor_vector is also indexed after model.odor_layers, therefore they agree\n                values_for_odor = self.secondary_values[self.model.odor_layer_names[i]]\n                max_stim = values_for_odor.argmax()\n                max_value = values_for_odor.max()\n                min_stim = values_for_odor.argmin()\n                min_value = values_for_odor.min()\n                #In the primary and secondary values arrayys, the [0] is reward and the [1] is punishment, both positive\n                if max_value > 0 :\n                    # BIO : The expected reward of an approaching action is a function of \n                    # BIO : the currently perceived stimulus strength and its reward value for the organism\n                    # BIO : \n                    #reward = self.hunger_status * value\n                    actions.loc[actions.index.max() + 1] = ['Approach', max_stim, temp[i][0] * self.hunger_status * max_value, self.approach, temp[i]]\n                if min_value < 0 : # & (isinstance (agent, Predator)) :\n                    actions.loc[actions.index.max() + 1] = ['Avoid', min_stim, (-1) * temp[i][0] * min_value, self.avoid, temp[i]]\n        return actions\n    \n    def add_feed_suffer_possibility(self, actions) :\n        cellmates = self.model.space.get_neighbors(self.pos, 1, include_center=True)\n        food_cellmates = [x for x in cellmates if isinstance (x, Food)]\n        predator_cellmates = [x for x in cellmates if isinstance (x, mouseworld.predator.Predator)]\n        if len(predator_cellmates) != 0:\n            for predator in predator_cellmates :\n                if np.random.uniform() > predator.escape_chance :\n                    value = self.primary_values[predator.group]\n                    actions.loc[actions.index.max() + 1] = ['Suffer', predator.group, value, self.suffer, predator]                  \n        if len(food_cellmates) != 0:\n            for food in food_cellmates :\n                value = self.primary_values[food.group]\n                actions.loc[actions.index.max() + 1] = ['Feed', food.group, self.hunger_status * value, self.feed, food]                  \n        return actions\n    \n    def check_inheritance(self, current_action, possible_actions) :\n        verb = current_action['Verb']\n        noun = current_action['Noun_group']\n        \n        if verb == 'Approach' :\n            a = possible_actions.loc[(possible_actions['Verb'] == 'Feed') & \n                                     (possible_actions['Noun_group'] == noun)]\n            b = possible_actions.loc[(possible_actions['Verb'] == 'Approach') & \n                                     (possible_actions['Noun_group'] == noun)]\n            if not a.empty :\n                self.action_history['Termination'][self.action_history.index.max()] = 'Closure'\n                return (a.loc[a['Value'].idxmax()])\n            elif b.empty :\n                self.action_history['Termination'][self.action_history.index.max()] = 'Failure'\n                return (None)\n            else :\n                return (None)\n            \n        elif verb == 'Avoid' :\n            a = possible_actions.loc[(possible_actions['Verb'] == 'Avoid') & \n                                     (possible_actions['Noun_group'] == noun)]\n            if a.empty :\n                self.action_history['Termination'][self.action_history.index.max()] = 'Closure'\n            return (None)   \n        elif verb == 'Search' :\n            a = possible_actions.loc[(possible_actions['Verb'] == 'Approach') & \n                                     (possible_actions['Value'] > 0)]\n            if not a.empty :\n                self.action_history['Termination'][self.action_history.index.max()] = 'Closure'\n                return (a.loc[a['Value'].idxmax()])\n            else :\n                return (None)\n        else :\n            return (None)\n        \n#     def evaluate(self, current_action, new_action) :\n#         if (current_action['Verb'][0] == new_action['Verb'][0]) & \n#         (current_action['Noun_group'][0] == new_action['Noun_group'][0]) :self.action_history.loc[self.action_history.index.max()]\n                \n    def decide(self, current_action, possible_actions) :\n        a = possible_actions.loc[(possible_actions['Verb'] == 'Suffer')]\n        if not a.empty :\n            return a.loc[a['Value'].idxmin()]\n        else :\n            temp = self.check_inheritance(current_action, possible_actions)       \n            if temp is not None :\n                return temp\n            else :\n                max_reward_action_ind = possible_actions['Value'].idxmax()\n                new_action = possible_actions.loc[max_reward_action_ind]\n                return new_action\n            \n            #max_reward = possible_actions['Value'].max()\n            \n#             max_reward = possible_actions['Reward_Value'].max()\n#             min_punishment = possible_actions['Punishment_Value'].min()\n#             if max_reward >= abs(min_punishment) :\n#                 max_reward_action_ind = possible_actions['Reward_Value'].idxmax()\n#                 new_action = possible_actions.loc[max_reward_action_ind]\n#             else :\n#                 min_punishment_action_ind = possible_actions['Punishment_Value'].idxmin()\n#                 new_action = possible_actions.loc[min_punishment_action_ind]\n            \n        #print(current_action)    \n        #print(new_action) \n        \n        \n        \n#         if (current_action['Verb'] == new_action['Verb']) & ((current_action['Noun_group'] is None) or (current_action['Noun_group'] == new_action['Noun_group'])):\n#             self.current_action['Duration'] += 1\n#         else :\n#             self.action_history.loc[self.action_history.index.max() + 1] = self.current_action\n#             self.current_action = pd.Series([new_action['Verb'], new_action['Noun_group'], 0, 0, False], \n#                                            index =('Verb', 'Noun_group', 'Duration', 'Benefit', 'Closure'))\n        \n#         return new_action\n    \n    def update_action_history(self, action, action_history) :\n        if action_history.empty :\n            action_history.loc[0] = [action['Verb'], action['Noun_group'], 1, 0, None, 0]\n        else :\n            last_action = action_history.loc[action_history.index.max()]\n            if (action['Verb'] == last_action['Verb']) & ((action['Noun_group'] is None) or (action['Noun_group'] == last_action['Noun_group'])):\n                action_history['Duration'][action_history.index.max()] += 1\n            else :\n                action_history.loc[action_history.index.max() + 1] = [action['Verb'], action['Noun_group'], 1, 0, None, 0]\n        return action_history\n        \n    def act(self, action) :\n        function = action['Function']\n        sig = signature(function)\n        num_args = len(sig.parameters)\n        if num_args == 0 :\n            function()\n        elif num_args == 1 :\n            arg = action['Arg_1']\n            function(arg)\n            \n    def wait(self) :\n        self.motor_vector = np.zeros(self.motor_num)\n        \n    def search_for_odor(self) :\n        if self.motor_NN_on :\n            self.input_manager.value = (0,0)\n            if self.learning_on :\n                self.input_manager.state = [0,-1,-1]\n            else :\n                self.input_manager.state = [-1,-1,-1]\n#             with self.mousebrain_sim :\n#                 self.mousebrain_sim.step()\n            for i in range(self.brain_iterations_per_step) :\n                self.mousebrain_sim.step()\n            #print(self.mousebrain_sim.data[self.mousebrain.p_search])\n            temp = self.mousebrain_sim.data[self.mousebrain.p_search]\n            self.motor_vector = np.mean(temp[-self.brain_iterations_per_step : ], axis = 0)\n            #print(self.motor_vector)\n        else :\n            #motor_vector = [random.uniform(0, 1)]*self.motor_num\n            self.motor_vector = [1,0]\n        #self.motor_vector = [1,0]\n    \n    def approach(self, goal_sense) :\n        #goal_sense = self.sensor_vector[odor_layer]\n        \n        if self.motor_NN_on :\n            self.input_manager.value = goal_sense\n            if self.learning_on :\n                self.input_manager.state = [-1,0,-1]\n            else :\n                self.input_manager.state = [-1,-1,-1]\n            \n#             with self.mousebrain_sim :\n#                 self.mousebrain_sim.step()\n            for i in range(self.brain_iterations_per_step) :\n                self.mousebrain_sim.step()\n            temp = self.mousebrain_sim.data[self.mousebrain.p_approach]\n            self.motor_vector = np.mean(temp[-self.brain_iterations_per_step : ], axis = 0)\n        else :\n            self.motor_vector = [np.exp(-goal_sense[0])-np.exp(-0.5), goal_sense[1]*10]\n        \n    def avoid(self, goal_sense) :\n        #goal_sense = self.sensor_vector[odor_layer]\n        \n        if self.motor_NN_on :\n            self.input_manager.value = goal_sense\n            if self.learning_on :\n                self.input_manager.state = [-1,-1,0]\n            else :\n                self.input_manager.state = [-1,-1,-1]\n            \n#             with self.mousebrain_sim :\n#                 self.mousebrain_sim.step()\n            for i in range(self.brain_iterations_per_step) :\n                self.mousebrain_sim.step()\n            temp = self.mousebrain_sim.data[self.mousebrain.p_avoid]\n            self.motor_vector = np.mean(temp[-self.brain_iterations_per_step : ], axis = 0)\n        else :\n            self.motor_vector = [np.exp(goal_sense[0])-0.9, -goal_sense[1]*10]\n            \n    def suffer(self,predator) :\n        \n        # BIO : ENERGY LOSS due to suffering\n        loss =  self.suffering_amount * predator.damage_level\n        self.energy -= loss\n        \n        # COUNTER\n        self.energy_to_predators += loss\n        self.action_history['Benefit'][self.action_history.index.max()] -= loss\n        \n        # BIO : LEARNING when suffering\n        self.primary_values[predator.group] += (-loss - self.primary_values[predator.group]) * self.primary_learning_rate\n        self.update_odor_values (predator.group)\n        \n        # TECH : Motion when suffering is 0.\n        self.motor_vector = np.zeros(self.motor_num)\n    \n    def feed(self, food) :\n        \n        # TECH : Feeding amount must be the minimum of [consumption per turn, space left in stomach and available food amount]\n        feeding_amount = self.feeding_amount\n        if feeding_amount > self.max_gastric_content-self.gastric_content :\n            self.action_history['Termination'][self.action_history.index.max()] = 'Saturation'\n            feeding_amount = self.max_gastric_content-self.gastric_content\n        if feeding_amount > food.food_amount :\n            self.action_history['Termination'][self.action_history.index.max()] = 'No food!'\n            feeding_amount = food.food_amount\n        food.food_amount -= feeding_amount\n                \n        # ENV : Nutritional value per unit is defined by the food parameter\n        gain = feeding_amount * food.nutritional_value\n        \n        # BIO : ENERGY BUFFER GAIN due to feeding\n        self.metabolism_buffer += gain\n        # BIO : STOMACH FILLING due to feeding\n        self.gastric_content += feeding_amount\n        \n        # COUNTER\n        if food.nutritional_value > 0 :\n            self.food_gained_energy += gain\n            #self.primary_values[food.group] = [gain, 0]\n        elif food.nutritional_value < 0 :\n            self.food_lost_energy -= gain\n            #self.primary_values[food.group] = [0,-gain]\n        self.action_history['Benefit'][self.action_history.index.max()] += gain\n        \n        # BIO : LEARNING when feeding\n        #self.secondary_values = self.update_odor_values(gain)\n        # set the new value for the specific food group. At a later stage it must be elaborated\n        self.primary_values[food.group] += (gain - self.primary_values[food.group]) * self.primary_learning_rate\n        self.update_odor_values(food.group)\n        \n        # TECH : Motion when feeding is 0. \n        self.motor_vector = np.zeros(self.motor_num)\n        \n    def update_odor_values (self, group) :\n        layer_names = self.model.odor_layer_names\n        vector = self.sensor_vector\n        primary_value = self.primary_values[group]\n        values_for_group = self.secondary_values.ix[group]\n        sum_values = sum(values_for_group)\n        error = primary_value - sum_values\n        \n        for i in range(len(vector)) :\n            if vector[i][0] > 0 :\n                \n                # BIO : Wikipedia on CLASSICAL CONDITIONING : The Rescorla-Wagner equation dV=a*b*(l-sum(V))\n                # BIO :  V represents the current associative strength of the CS\n                # BIO : dV is the change in this strength that happens on a given trial\n                # BIO : sum(V) is the sum of the strengths of all stimuli present in the situation. \n                # BIO : l is the maximum associative strength that a given US will support; \n                # BIO : its value is usually set to 1 on trials when the US is present, and 0 when the US is absent\n                # BIO : a and b are constants related to the salience of the CS and the speed of learning for a given US\n                \n                # BIO : a is the value of a specific odor at the point where conditioning occurs\n                # BIO : b is the learning rate\n                # BIO : \n                \n                values_for_group[layer_names[i]] += error * vector[i][0] * self.secondary_learning_rate \n            else :\n                continue\n            \n        #return secondary_values\n    \n    def move(self, motor_vector) :\n        \n        # BIO : Translate motor signal to behavior (how much to turn, how much to move)\n        distance = motor_vector[0] * self.max_speed\n        self.header = (self.header + motor_vector[1] * math.pi)%(2*math.pi)\n        \n        # COUNTER\n        self.total_distance += distance\n        self.action_history['Distance'][self.action_history.index.max()] += distance\n        \n        # TECH : Move the agent\n        new_pos = (self.pos[0] + math.cos(self.header) * distance, self.pos[1] + math.sin(self.header) * distance)\n        self.model.space.move_agent(self, self.model.space.torus_adj(new_pos))\n        \n        return distance\n    \n    def pay_metabolic_cost(self, pregnant, distance) :\n        old_energy = self.energy\n        \n        # BIO : KATABOLISM RATE\n        self.energy += (1 - self.metabolism_rate) * self.metabolism_buffer\n        if self.energy >= self.max_energy :\n            self.energy = self.max_energy\n        self.metabolism_buffer = self.metabolism_rate * self.metabolism_buffer\n        if pregnant:\n            self.energy -= (1 + distance)*2\n        else :\n            self.energy -= 1 + distance\n        self.energy_change = self.energy - old_energy\n        #self.current_action['Energy_loss'] +=\n        self.gastric_content = 0.95 * self.gastric_content\n        self.hunger_status = abs((1 * self.max_gastric_content - self.gastric_content)) / (1 * self.max_gastric_content)\n    \n    def step(self):\n        if self.energy <= 0 :\n            self.die()\n        else :\n            if (self.age >= self.maturity_age and self.pregnant == False) :\n                self.conceive()\n            if (self.pregnant) :\n                self.incubation_time += 1\n                if self.incubation_time >= self.incubation_period :\n                    self.give_birth()\n            self.possible_actions = pd.DataFrame(self.trivial_actions, \n                                                     columns=('Verb', 'Noun_group', 'Value', 'Function', 'Arg_1'))\n            self.sensor_position = self.set_sensor_position(self.pos, self.header)\n            self.sensor_vector = self.sense(self.sensor_position)\n            self.possible_actions = self.update_possible_actions(self.possible_actions)\n            self.possible_actions = self.add_feed_suffer_possibility(self.possible_actions)\n            self.current_action = self.decide(self.current_action, self.possible_actions)\n            self.action_history = self.update_action_history(self.current_action, self.action_history)\n            self.act(self.current_action)\n            distance = self.move(self.motor_vector)\n            self.pay_metabolic_cost (self.pregnant, distance)\n            self.age += 1\n            ")


# In[12]:

get_ipython().run_cell_magic('writefile', 'mouseworld/mousebrain.py', '\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n#import mouseworld.mouse\nfrom mouseworld.input_manager import Input_manager\n\n#from mouseworld.mouse import Input_manager\nimport nengo\n\nclass Mousebrain(nengo.Network) :\n    \n    def approach(self, x):\n        spd = np.exp(-x[0])-np.exp(-0.5)\n        turn = x[1]*10\n        return spd, turn\n\n    def avoid(self, x) :\n        spd = np.exp(x[0])-0.9    \n        turn = -x[1]*10      \n        return spd, turn\n\n    def search(self, x) :\n        spd = 1\n        turn = 0\n        return spd, turn\n\n    \n    def build(self, input_manager):\n\n        #mousebrain  = nengo.Network()\n        with self:\n            odor = nengo.Node(input_manager.return_value,size_out = 2)\n\n            state = nengo.Node(input_manager.return_state,size_out = 3)\n\n            odor_neurons = nengo.Ensemble(n_neurons=50, dimensions=2, radius=1)\n            nengo.Connection(odor, odor_neurons, synapse = None)\n\n            odor_memory = nengo.Ensemble(n_neurons=200, dimensions=2)\n            nengo.Connection(odor[0], odor_memory[0], transform = 1, synapse=None)\n            nengo.Connection(odor_memory[0], odor_memory[1], transform = 1, synapse=0.3)\n            #nengo.Connection(odor_memory[1], odor_memory[0], transform = -0.5, synapse=0.3)\n\n            odor_change = nengo.Ensemble(n_neurons = 200, dimensions = 1, radius=0.1,  \n                            max_rates=nengo.dists.Uniform(300, 400), intercepts=nengo.dists.Uniform(0, 0.1))\n            nengo.Connection(odor_memory[0], odor_change, transform = 1, synapse=0.01)\n            nengo.Connection(odor_memory[1], odor_change, transform = -1, synapse=0.01)\n            #nengo.Connection(odor_neurons[0], odor_change, transform = -0.1, synapse=0.1)\n\n            #hub = nengo.Node(size_in = 1,size_out=3)\n            errors = nengo.networks.EnsembleArray(n_neurons=100, n_ensembles=3, ens_dimensions=2)\n            #nengo.Connection(odor_change, hub)\n            nengo.Connection(odor_change, errors.input, transform = [[1]]*6, synapse=0.1)\n            nengo.Connection(state[0], errors.ensembles[0].neurons, transform=np.ones((100,1))*1)\n            nengo.Connection(state[1], errors.ensembles[1].neurons, transform=np.ones((100,1))*1)\n            nengo.Connection(state[2], errors.ensembles[2].neurons, transform=np.ones((100,1))*1)\n\n            #nengo.Connection(odor_memory, odor_change[0], transform = -10, synapse=None)\n            #nengo.Connection(odor_neurons[0], odor_change[0], transform = 10, synapse=None)\n            #nengo.Connection(odor_memory, odor_change[1], transform = -10, synapse=None)\n            #nengo.Connection(odor_neurons[0], odor_change[1], transform = 10, synapse=None)\n\n            #reward = nengo.Node(size_in = 1)\n            #nengo.Connection(odor_memory, reward, transform = -10, synapse=0.05)\n            #nengo.Connection(odor_neurons[0], reward, transform = 10, synapse=0.05)\n\n            #odor2motor = nengo.Ensemble(n_neurons=100, dimensions=2, radius=2, seed=2, \n            # yy          noise=nengo.processes.WhiteSignal(10, 0.1, rms=1))\n            #odor2motor = nengo.Ensemble(n_neurons=200, dimensions=3, radius=2)\n\n            #nengo.Connection(odor_change, odor2motor[0],synapse=0.01)\n\n            approach_neurons = nengo.Ensemble(n_neurons=200, dimensions=2)\n            avoid_neurons = nengo.Ensemble(n_neurons=200, dimensions=2)\n            search_neurons = nengo.Ensemble(n_neurons=200, dimensions=2)\n            #nengo.Connection(odor_neurons[0], odor2motor[0],synapse=0.01)\n            #nengo.Connection(odor_neurons[1], odor2motor[1],synapse=0.01)\n\n            approach_node = nengo.Node(size_in=2, size_out = 2)\n            avoid_node = nengo.Node(size_in=2, size_out = 2)\n            search_node = nengo.Node(size_in=2, size_out = 2)\n\n            # Arbitrary, intuitive functions are implemented as initialization for the various ensembles.\n            # Input: x[0] for mean stimulus strength (higher when closer to the source)\n            # Input: x[1] for left-right stimulus (positive when source to the left)\n            # Turning is implemented by default to the right\n            # When approaching we need high speed when low input and turning towards source\n            \n            #nengo.Connection(odor2motor, motor_neurons, function=braiten) \n            conn_approach = nengo.Connection(odor_neurons, approach_neurons, function=self.approach, \n                        learning_rule_type=nengo.PES(learning_rate=1e-4, pre_tau=0.1))\n            conn_avoid = nengo.Connection(odor_neurons, avoid_neurons, function=self.avoid, \n                        learning_rule_type=nengo.PES(learning_rate=1e-4, pre_tau=0.1))\n            conn_search = nengo.Connection(odor_neurons, search_neurons, function=self.search, \n                        learning_rule_type=nengo.PES(learning_rate=1e-4, pre_tau=0.1))\n\n            nengo.Connection(errors.ensembles[0], conn_approach.learning_rule, synapse = 0.01)\n            nengo.Connection(errors.ensembles[1], conn_avoid.learning_rule, synapse = 0.01)\n            nengo.Connection(errors.ensembles[2], conn_search.learning_rule, synapse = 0.01)\n\n\n\n            nengo.Connection(approach_neurons, approach_node) \n            nengo.Connection(avoid_neurons, avoid_node) \n            nengo.Connection(search_neurons, search_node) \n            #learning = nengo.Node(size_out = 2, output = [-1,-1])\n            #nengo.Connection(learning, conn.learning_rule, synapse=None)  \n\n#             mousebrain.p_approach = nengo.Probe(approach_node)\n#             mousebrain.p_avoid = nengo.Probe(avoid_node)\n#             mousebrain.p_search = nengo.Probe(search_node)\n\n            self.p_approach = nengo.Probe(approach_node)\n            self.p_avoid = nengo.Probe(avoid_node)\n            self.p_search = nengo.Probe(search_node)\n            self.p_odor = nengo.Probe(odor)\n            self.p_state = nengo.Probe(state)\n            self.p_change = nengo.Probe(odor_change)\n            self.p_errors0 = nengo.Probe(errors.ensembles[0])\n            self.p_errors1 = nengo.Probe(errors.ensembles[1])\n            self.p_errors2 = nengo.Probe(errors.ensembles[2])\n            \n        #return mousebrain')


# In[46]:

get_ipython().run_cell_magic('writefile', 'mouseworld/predator.py', "\nfrom mesa import Agent, Model\n#from mesa.time import RandomActivation\n#from mesa.space import ContinuousSpace\nfrom mouseworld.myspace import ContinuousSpace\nimport mouseworld.mouse \n#import Mouse\n\nimport math\nimport numpy as np\n\nclass Predator(Agent):\n    \n    def __init__(self, group, group_num, odor_layer, model):\n        #super().__init__(unique_id, model)\n        self.model = model\n        self.unique_id = model.give_next_id('Predator')\n        self.group = group\n        self.group_num = group_num\n        self.odor_layer = odor_layer\n        self.victims_num = 0\n        temp_predator_param_comb = self.model.predator_param_combs[group_num]\n        self.get_params(temp_predator_param_comb)\n        self.escape_chance = 0.1\n        \n    def get_params(self, params) :\n        self.odor_strength = params[0]\n        self.odor_std = params[1]\n        self.damage_level = params[2]\n        self.hunt_rule = params[3]\n        self.hunt_radius = params[4]\n        \n    def move_naive(self):\n        # move by 1 towards a random direction\n        header = np.random.uniform (low = 0.0, high = math.pi*2)\n        new_position = (self.pos[0] + math.cos(header), self.pos[1] + math.sin(header))\n        self.model.space.move_agent(self, new_position)\n    \n    def move_smart(self):\n        # move by 1 towards a random mouse within 3 radius\n        neighbors = self.model.space.get_neighbors(self.pos, self.hunt_radius*3, include_center=True)\n        neighbor_mice = [x for x in neighbors if isinstance (x, mouseworld.mouse.Mouse)]\n        if len(neighbor_mice) != 0:\n            unlucky_mouse = np.random.choice(neighbor_mice)\n            distance = self.model.space.get_distance(unlucky_mouse.pos, self.pos)\n            trans_vector = [(unlucky_mouse.pos[0] - self.pos[0])/distance,(unlucky_mouse.pos[1] - self.pos[1])/distance]\n            new_position = (self.pos[0] + trans_vector[0], self.pos[1] + trans_vector[1])\n            self.model.space.move_agent(self, new_position)\n        else :\n            self.move_naive()\n        \n    def find_mice(self):\n        cellmates = self.model.space.get_neighbors(self.pos, self.hunt_radius, include_center=True)\n        mice_cellmates = [x for x in cellmates if isinstance (x, mouseworld.mouse.Mouse)]\n        #self.model.space._grid.iter_cell_list_contents(self.model.space._point_to_cell(self.pos))\n        return mice_cellmates\n        #if len(mice_cellmates) != 0:\n            #self.hungry = False\n            #self.victims_num += 1\n            #return True\n#             for o in mice_cellmates :\n#                 self.victims_num += 1\n#                 loss = o.energy * self.damage_level\n#                 o.energy -= loss\n#                 o.primary_values[self.group] = [0, loss]\n#                 o.secondary_values[self.odor_layer] = o.primary_values[self.group]\n    \n    def step(self):\n        #self.hungry = True\n        mice_cellmates = self.find_mice\n        if not mice_cellmates :\n            if self.hunt_rule == 0 :\n                self.move_naive()\n            elif self.hunt_rule == 1 :\n                self.move_smart()\n        #self.find_mice\n        grid_pos = self.model.space._point_to_cell(self.pos)\n        self.odor_layer.add_value(grid_pos, self.odor_strength)\n        #self.odor_layer.update_agent_location(self.unique_id, self.pos)\n        #self.model.show_odor_to_mice(self)\n        #self.model.odor_matrix['predator_odor_%i'%(self.group_num)][self.pos[0]][self.pos[1]] = self.odor_strength\n        ")


# In[47]:

get_ipython().run_cell_magic('writefile', 'mouseworld/food.py', "\nfrom mesa import Agent, Model\n#from mesa.time import RandomActivation\n#from mesa.space import ContinuousSpace\nfrom mouseworld.myspace import ContinuousSpace\n\nimport random\n\nclass Food(Agent):\n    \n    def __init__(self, group, group_num, odor_layer, food_amount_range, model):\n        self.model = model\n        self.unique_id = model.give_next_id('Food')\n        self.group = group\n        self.group_num = group_num\n        self.odor_layer = odor_layer\n        self.food_amount = random.randint(food_amount_range[0],food_amount_range[1])\n        temp_food_param_comb = self.model.food_param_combs[group_num]\n        self.get_params(temp_food_param_comb)\n        \n    def get_params(self, params) :\n        self.odor_strength = params[0]\n        self.nutritional_value = params[1]\n        self.odor_std = params[2]   \n    \n    def replace(self) :\n        self.model.space.remove_agent(self)\n        self.model.food_schedule.remove(self)\n        #self.odor_layer.remove_agent(self)\n        # for now we replace food\n        food = Food(self.group, self.group_num, self.odor_layer, self.model.food_amount_range, self.model)\n        \n        self.model.place_agent_randomly(food)\n        self.model.food_schedule.add(food)\n        #self.odor_layer.add_agent(self)\n        \n    def step(self):\n        if self.food_amount <= 0 :\n            self.replace()\n        else :\n            grid_pos = self.model.space._point_to_cell(self.pos)\n            self.odor_layer.add_value(grid_pos, self.odor_strength)            \n            #self.model.show_odor_to_mice(self)\n            #self.model.odor_matrix['food_odor_%i'%(self.group_num)][self.pos[0]][self.pos[1]] = self.odor_strength")


# ### 

# In[ ]:



